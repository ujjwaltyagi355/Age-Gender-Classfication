# -*- coding: utf-8 -*-
"""AGE_MODEL_TRAIN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wB1ccPKZfQGviCJOfldDrK3Gap3vraBW
"""

import torch
import matplotlib.pyplot as plt
import numpy as np
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import tensorflow as tf
from tensorflow import keras
import os
import pandas as pd
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense

device = device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

# Initializing a Sequential model
age = Sequential()

# Creating first block- (2 Convolution + 1 Max pool)
age.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same', input_shape= (224, 224, 3), activation= 'relu'))
age.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating second block- (2 Convolution + 1 Max pool)
age.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating third block- (3 Convolution + 1 Max pool)
age.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating fourth block- (3 Convolution + 1 Max pool)
age.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating fifth block- (3 Convolution + 1 Max pool)
age.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
age.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Flattening the pooled image pixels
age.add(Flatten())

# Creating 2 Dense Layers
age.add(Dense(units= 4096, activation='relu'))
age.add(Dense(units= 4096, activation='relu'))

# Creating an output layer
age.add(Dense(units= 9, activation='softmax'))

# Getting the summary of the model
age.summary()

# Compiling the model
age.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

from PIL import Image

def preprocess(path):
  image = Image.open(path)
  image = image.resize((224, 224))
  return np.array(image)

!git clone https://github.com/circulosmeos/gdown.pl.git

!./gdown.pl/gdown.pl https://drive.google.com/file/d/0BxYys69jI14kb2o4ajJwQ3FOUm8/edit part1.tar.gz

!./gdown.pl/gdown.pl https://drive.google.com/file/d/0BxYys69jI14kNEt1SnNJN1Z2WWc/edit part2.tar.gz

!./gdown.pl/gdown.pl https://drive.google.com/file/d/0BxYys69jI14kVkVTZHZHa21zUXM/edit part3.tar.gz

import tarfile
my_tar = tarfile.open('part1.tar.gz')
my_tar.extractall('./part1') # specify which folder to extract to
my_tar.close()

my_tar = tarfile.open('part2.tar.gz')
my_tar.extractall('./part2') # specify which folder to extract to
my_tar.close()

my_tar = tarfile.open('part3.tar.gz')
my_tar.extractall('./part3') # specify which folder to extract to
my_tar.close()

!ls part1/part1

!./gdown.pl/gdown.pl https://drive.google.com/file/d/1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH/edit train.csv

!./gdown.pl/gdown.pl https://drive.google.com/file/d/1Z1RqRo0_JiavaZw2yzZG6WETdZQ8qX86/edit dataset.zip

!unzip dataset.zip

Image.open('part1/part1/3_1_3_20161219230521112.jpg')

!./gdown.pl/gdown.pl https://drive.google.com/file/d/1wOdja-ezstMEp81tX1a-EYkFebev4h7D/edit val.csv

path = 'part1/part1/'
input = []
output = []
for filename in os.listdir(path):
  if filename.endswith(".jpg"): 
    if (filename.split('_')[2] == '3'):
      actual_age = int(filename.split('_')[0])
      if(actual_age>=0 and actual_age <=2):
        output.append(0)
      elif (actual_age>=3 and actual_age <= 9):
        output.append(1)
      elif (actual_age>9 and actual_age<=19):
        output.append(2)
      elif (actual_age>19 and actual_age<=29):
        output.append(3)
      elif (actual_age>29 and actual_age<=39):
        output.append(4)
      elif (actual_age>39 and actual_age<=49):
        output.append(5)
      elif (actual_age>49 and actual_age<=59):
        output.append(6)
      elif (actual_age>59 and actual_age<=69):
        output.append(7)
      else:
        output.append(8)
      input.append(preprocess(path+filename))
    continue
  else:
    continue

path = 'part2/part2/'
for filename in os.listdir(path):
  if filename.endswith(".jpg"): 
    if (filename.split('_')[2] == '3'):
      actual_age = int(filename.split('_')[0])
      if(actual_age>=0 and actual_age <=2):
        output.append(0)
      elif (actual_age>=3 and actual_age <= 9):
        output.append(1)
      elif (actual_age>9 and actual_age<=19):
        output.append(2)
      elif (actual_age>19 and actual_age<=29):
        output.append(3)
      elif (actual_age>29 and actual_age<=39):
        output.append(4)
      elif (actual_age>39 and actual_age<=49):
        output.append(5)
      elif (actual_age>49 and actual_age<=59):
        output.append(6)
      elif (actual_age>59 and actual_age<=69):
        output.append(7)
      else:
        output.append(8)
      input.append(preprocess(path+filename))
    continue
  else:
    continue

path = 'part3/part3/'
for filename in os.listdir(path):
  if filename.endswith(".jpg"): 
    if (filename.split('_')[2] == '3'):
      actual_age = int(filename.split('_')[0])
      if (actual_age>=0 and actual_age <=2):
        output.append(0)
      elif (actual_age>=3 and actual_age <= 9):
        output.append(1)
      elif (actual_age>9 and actual_age<=19):
        output.append(2)
      elif (actual_age>19 and actual_age<=29):
        output.append(3)
      elif (actual_age>29 and actual_age<=39):
        output.append(4)
      elif (actual_age>39 and actual_age<=49):
        output.append(5)
      elif (actual_age>49 and actual_age<=59):
        output.append(6)
      elif (actual_age>59 and actual_age<=69):
        output.append(7)
      else:
        output.append(8)
      input.append(preprocess(path+filename))
    continue
  else:
    continue

dataset_train = pd.read_csv('train.csv')
dataset_train.head()

for ind in dataset_train.index: 
  if(dataset_train['race'][ind] != 'Indian'):
    continue
  path = dataset_train['file'][ind]
  actual_age = dataset_train['age'][ind]
  if (actual_age == '0-2'):
    actual_age = 0
  elif (actual_age == '3-9'):
    actual_age = 1
  elif (actual_age == '10-19'):
    actual_age = 2
  elif (actual_age == '20-29'):
    actual_age = 3    
  elif (actual_age == '30-39'):
    actual_age = 4    
  elif (actual_age == '40-49'):
    actual_age = 5    
  elif (actual_age == '50-59'):
    actual_age = 6
  elif (actual_age == '60-69'):
    actual_age = 7
  elif (actual_age == 'more than 70'):
    actual_age = 8
  input.append(preprocess(path))
  output.append(actual_age)

print(len(input), len(output))
input = np.asarray(input)
output = np.asarray(output)
b = np.zeros((output.size, output.max()+1))
b[np.arange(output.size),output] = 1
output = b

# Fitting the model
age.fit(input, output, batch_size=128, epochs=25, validation_split =0.20, shuffle=True)

age_classes = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', 'more than 70']

def age_predict(path):
  l = []
  l.append(preprocess(path))
  l = np.asarray(l)
  prediction = age.predict(l)[0]
  return np.argmax(prediction)



age_predict('part1/part1/3_1_3_20161219230521112.jpg')

validation = pd.read_csv('val.csv')
validation.head()

validation['race'].value_counts()

rows, cols = (9, 9) 
age_vs_age = [[0 for i in range(cols)] for j in range(rows)] 
for ind in validation.index: 
  if(validation['race'][ind] != 'Indian'):
    continue
  print(ind)
  path = validation['file'][ind]
  actual_age = validation['age'][ind]
  if (actual_age == '0-2'):
    actual_age = 0
  elif (actual_age == '3-9'):
    actual_age = 1
  elif (actual_age == '10-19'):
    actual_age = 2
  elif (actual_age == '20-29'):
    actual_age = 3    
  elif (actual_age == '30-39'):
    actual_age = 4    
  elif (actual_age == '40-49'):
    actual_age = 5    
  elif (actual_age == '50-59'):
    actual_age = 6
  elif (actual_age == '60-69'):
    actual_age = 7
  elif (actual_age == 'more than 70'):
    actual_age = 8
  predicted_age = age_predict(path)
  age_vs_age[actual_age][predicted_age]+=1

for row in age_vs_age:
  print(row)

!pip install h5py

# serialize model to JSON
model_json = age.to_json()
with open("age.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
age.save_weights("age.h5")
print("Saved model to disk")