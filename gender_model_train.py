# -*- coding: utf-8 -*-
"""Gender_MODEL_TRAIN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b0ZXYTAm5Z3YmwhaTipBptThupzHJcRD

## Importing the liabraries
"""

import torch
import matplotlib.pyplot as plt
import numpy as np
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import tensorflow as tf
from tensorflow import keras
import os
import pandas as pd
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense

device = device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

"""## VGG-16 Gender Model"""

# Initializing a Sequential model
gender = Sequential()

# Creating first block- (2 Convolution + 1 Max pool)
gender.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same', input_shape= (224, 224, 3), activation= 'relu'))
gender.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating second block- (2 Convolution + 1 Max pool)
gender.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating third block- (3 Convolution + 1 Max pool)
gender.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating fourth block- (3 Convolution + 1 Max pool)
gender.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Creating fifth block- (3 Convolution + 1 Max pool)
gender.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same', activation= 'relu'))
gender.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))

# Flattening the pooled image pixels
gender.add(Flatten())

# Creating 2 Dense Layers
gender.add(Dense(units= 4096, activation='relu'))
gender.add(Dense(units= 4096, activation='relu'))

# Creating an output layer
gender.add(Dense(units= 2, activation='softmax'))

# Getting the summary of the model
gender.summary()

# Compiling the model
gender.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""## Image Preprocessing"""

from PIL import Image

def preprocess(path):
  image = Image.open(path)
  image = image.resize((224, 224))
  return np.array(image)

"""# Downloading dataset"""

!git clone https://github.com/circulosmeos/gdown.pl.git

!./gdown.pl/gdown.pl https://drive.google.com/file/d/0BxYys69jI14kb2o4ajJwQ3FOUm8/edit part1.tar.gz

!./gdown.pl/gdown.pl https://drive.google.com/file/d/0BxYys69jI14kNEt1SnNJN1Z2WWc/edit part2.tar.gz

!./gdown.pl/gdown.pl https://drive.google.com/file/d/0BxYys69jI14kVkVTZHZHa21zUXM/edit part3.tar.gz

import tarfile
my_tar = tarfile.open('part1.tar.gz')
my_tar.extractall('./part1') # specify which folder to extract to
my_tar.close()

my_tar = tarfile.open('part2.tar.gz')
my_tar.extractall('./part2') # specify which folder to extract to
my_tar.close()

my_tar = tarfile.open('part3.tar.gz')
my_tar.extractall('./part3') # specify which folder to extract to
my_tar.close()

!ls part1/part1

!./gdown.pl/gdown.pl https://drive.google.com/file/d/1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH/edit train.csv

!./gdown.pl/gdown.pl https://drive.google.com/file/d/1Z1RqRo0_JiavaZw2yzZG6WETdZQ8qX86/edit dataset.zip

!unzip dataset.zip

Image.open('part1/part1/3_1_3_20161219230521112.jpg')

"""## Train the Gender model"""

path = 'part1/part1/'
input = []
output = []
for filename in os.listdir(path):
  if filename.endswith(".jpg"): 
    if (filename.split('_')[2] == '3'):
      input.append(preprocess(path+filename))
      output.append(int(filename.split('_')[1]))
    continue
  else:
    continue

path = 'part2/part2/'
for filename in os.listdir(path):
  if filename.endswith(".jpg"): 
    if (filename.split('_')[2] == '3'):
      input.append(preprocess(path+filename))
      output.append(int(filename.split('_')[1]))
    continue
  else:
    continue

path = 'part3/part3/'
for filename in os.listdir(path):
  if filename.endswith(".jpg"): 
    if (filename.split('_')[2] == '3'):
      input.append(preprocess(path+filename))
      output.append(int(filename.split('_')[1]))
    continue
  else:
    continue

dataset_train = pd.read_csv('train.csv')
dataset_train.head()

dataset_train['race'].value_counts()

for ind in dataset_train.index: 
  if(dataset_train['race'][ind] != 'Indian'):
    continue
  path = dataset_train['file'][ind]
  actual_gender = (0, 1) [dataset_train['gender'][ind] == "Male"]
  input.append(preprocess(path))
  output.append(actual_gender)

print(len(input), len(output))
input = np.asarray(input)
output = np.asarray(output)
b = np.zeros((output.size, output.max()+1))
b[np.arange(output.size),output] = 1
output = b

gender_classes = ['Male', 'Female']

gender.fit(input, output, batch_size=128, epochs=20, validation_split =0.25, shuffle=True)

def gender_predict(path):
  l = []
  l.append(preprocess(path))
  l = np.asarray(l)
  prediction = gender.predict(l)[0]
  return np.argmax(prediction)

gender_predict('part1/part1/3_1_3_20161219230521112.jpg')

"""## Download prediction dataset"""

!./gdown.pl/gdown.pl https://drive.google.com/file/d/1wOdja-ezstMEp81tX1a-EYkFebev4h7D/edit val.csv

"""## Testing Gender Predictions"""

validation = pd.read_csv('val.csv')
validation.head()

validation['race'].value_counts()

rows, cols = (2, 2) 
gender_vs_gender = [[0 for i in range(cols)] for j in range(rows)]              # TM, FM, TF, FF
for ind in validation.index: 
  if(validation['race'][ind] != 'Indian'):
    continue
  print(ind)
  path = validation['file'][ind]
  actual_gender = (0, 1) [validation['gender'][ind] == "Male"]
  predicted_gender = gender_predict(path)
  if (predicted_gender == 0 and actual_gender == 0):
    gender_vs_gender[0][0]+=1
  elif (predicted_gender == 0 and actual_gender == 1):
    gender_vs_gender[0][1]+=1
  elif (predicted_gender == 1 and actual_gender == 1):
    gender_vs_gender[1][1]+=1
  else:
    gender_vs_gender[1][0]+=1

for row in gender_vs_gender:
  print(row)

!pip install h5py

# serialize model to JSON
model_json = gender.to_json()
with open("gender.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
gender.save_weights("gender.h5")
print("Saved model to disk")

